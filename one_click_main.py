
import os
import time
import re
import json
import logging
from expert_scrutinizer import (
    _audit_linguistic_quality,
    _audit_design_and_image,
    _validate_technical_constraints,
    _manage_persona_context,
    _audit_image_placement,
    _generate_blog_tags
)
from dotenv import load_dotenv

# --- Configuration ---
INPUT_DIR = "input"
OUTPUT_DIR = "output"
REFERENCES_DIR = "references"
MAX_RETRIES = 5

# Custom Logger for 'Breathing' with the Agent
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Speech Register Definitions (6ê°€ì§€ ì–´ì²´) ---
# Agentê°€ ì½˜í…ì¸  ë¶„ì„ í›„ ìë™ ì„ íƒí•  ë•Œ ì°¸ì¡°
SPEECH_REGISTERS = {
    1: {
        'name': 'í•´ë¼ì²´',
        'level': 1,
        'description': 'ë°˜ë§ ì¤‘ ê°€ì¥ ë‚®ì€ ê²©ì‹ì²´. ê¶Œìœ„ìˆëŠ” í•™ìˆ /ì „ë¬¸ ë¸”ë¡œê·¸ì— ì í•©.',
        'keywords': ['í•™ìˆ ', 'ì „ë¬¸', 'ë…¼ë¬¸', 'ë¶„ì„', 'ì—°êµ¬', 'ë©”ì»¤ë‹ˆì¦˜'],
        'examples': {
            'í‰ì„œ': ['-ë‹¤', '-ã„´ë‹¤/ëŠ”ë‹¤', '-ì•˜/ì—ˆë‹¤', '-ë”ë¼', '-êµ¬ë‚˜', '-êµ°'],
            'ì˜ë¬¸': ['-ëƒ?', '-ëŠëƒ?', '-ë‹ˆ?', '-ã„¹ê¹Œ?'],
            'ëª…ë ¹': ['-ì•„ë¼/ì–´ë¼', '-ê±°ë¼', '-ë ´'],
            'ì²­ìœ ': ['-ì']
        }
    },
    2: {
        'name': 'í•´ì²´',
        'level': 2,
        'description': 'ì¹œê·¼í•œ ë°˜ë§. ì¼ìƒì ì´ê³  ìºì£¼ì–¼í•œ ë¸”ë¡œê·¸ì— ì í•©.',
        'keywords': ['ì¼ìƒ', 'ì¹œê·¼', 'ìºì£¼ì–¼', 'ê²½í—˜ë‹´', 'í›„ê¸°'],
        'examples': {
            'í‰ì„œ': ['-ì–´/ì•„', '-ì§€', '-ê±°ë“ ', '-ë„¤', '-ëŠ”ë°', '-ì–ì•„', '-ë”ë¼ê³ '],
            'ì˜ë¬¸': ['-ì–´?/ì•„?', '-ì§€?', '-ëŠ”ë°?'],
            'ëª…ë ¹': ['-ì–´/ì•„'],
            'ì²­ìœ ': ['-ì–´/ì•„']
        }
    },
    3: {
        'name': 'í•˜ê²Œì²´',
        'level': 3,
        'description': 'ì˜ˆìŠ¤ëŸ¬ìš´ í•˜ëŒ€. ì¤‘ë…„ì¸µ ì´ìƒ ë˜ëŠ” ë³µê³ í’ ë¸”ë¡œê·¸ì— ì í•©.',
        'keywords': ['ë³µê³ ', 'ê³ ì „', 'ì—­ì‚¬', 'ì „í†µ'],
        'examples': {
            'í‰ì„œ': ['-ë„¤', '-ê² ë„¤', '-ã„´ê°€/ëŠ”ê°€'],
            'ì˜ë¬¸': ['-ë‚˜?', '-ëŠ”ê°€?', '-ë˜ê°€?'],
            'ëª…ë ¹': ['-ê²Œ', '-ê²Œë‚˜'],
            'ì²­ìœ ': ['-ì„¸', '-ì„¸ë‚˜']
        }
    },
    4: {
        'name': 'í•˜ì˜¤ì²´',
        'level': 4,
        'description': 'ì˜ˆìŠ¤ëŸ¬ìš´ ì¡´ëŒ€. ì‚¬ê·¹í’ì´ë‚˜ ê²©ì‹ìˆëŠ” ë³µê³  ìŠ¤íƒ€ì¼ì— ì í•©.',
        'keywords': ['ì‚¬ê·¹', 'ì—­ì‚¬ì ', 'ê²©ì‹'],
        'examples': {
            'í‰ì„œ': ['-ì˜¤', '-ì†Œ', '-ë¦¬ì˜¤', '-êµ¬ë ¤'],
            'ì˜ë¬¸': ['-ì˜¤?', '-ì†Œ?'],
            'ëª…ë ¹': ['-ì‹œì˜¤'],
            'ì²­ìœ ': ['-ã…‚ì‹œë‹¤', 'í•©ì‹œë‹¤']
        }
    },
    5: {
        'name': 'í•´ìš”ì²´',
        'level': 5,
        'description': 'ë¶€ë“œëŸ¬ìš´ ì¡´ëŒ“ë§. ì¹œê·¼í•˜ë©´ì„œë„ ì˜ˆì˜ìˆëŠ” ì¼ë°˜ ë¸”ë¡œê·¸ì— ì í•©.',
        'keywords': ['ì¹œì ˆ', 'ì•ˆë‚´', 'íŠœí† ë¦¬ì–¼', 'ê°€ì´ë“œ', 'ì„¤ëª…'],
        'examples': {
            'í‰ì„œ': ['-ì–´ìš”/ì•„ìš”', '-ì—ìš”/ì˜ˆìš”', '-ì£ ', '-ì§€ìš”', '-ë„¤ìš”', '-ê±°ë“ ìš”'],
            'ì˜ë¬¸': ['-ì–´ìš”?/ì•„ìš”?', '-ì£ ?', '-ë‚˜ìš”?', '-ã„¹ê¹Œìš”?'],
            'ëª…ë ¹': ['-ì„¸ìš”', '-ì£¼ì„¸ìš”'],
            'ì²­ìœ ': ['-ì–´ìš”/ì•„ìš”', '-ã„¹ë˜ìš”']
        }
    },
    6: {
        'name': 'í•˜ì‹­ì‹œì˜¤ì²´',
        'level': 6,
        'description': 'ê°€ì¥ ê²©ì‹ìˆëŠ” ì¡´ëŒ“ë§. ê³µì‹ì /ë¹„ì¦ˆë‹ˆìŠ¤ ë¸”ë¡œê·¸ì— ì í•©.',
        'keywords': ['ê³µì‹', 'ë¹„ì¦ˆë‹ˆìŠ¤', 'ê¸°ì—…', 'ë³´ê³ ì„œ', 'ë°œí‘œ'],
        'examples': {
            'í‰ì„œ': ['-ìŠµë‹ˆë‹¤/ã…‚ë‹ˆë‹¤', '-ì…ë‹ˆë‹¤', '-ê² ìŠµë‹ˆë‹¤'],
            'ì˜ë¬¸': ['-ìŠµë‹ˆê¹Œ?/ã…‚ë‹ˆê¹Œ?', '-ì…ë‹ˆê¹Œ?'],
            'ëª…ë ¹': ['-ì‹­ì‹œì˜¤', '-ì†Œì„œ'],
            'ì²­ìœ ': ['-ì‹­ì‹œë‹¤']
        }
    }
}


def signal(msg):
    """Signals to the Agent in the terminal to maintain synchronization."""
    print(f"\n[AGENT-PULSE] {msg}")
    time.sleep(0.5)


def read_input(filename):
    """Read file from input directory."""
    with open(os.path.join(INPUT_DIR, filename), 'r', encoding='utf-8') as f:
        return f.read()


def read_reference(filename):
    """Read file from references directory."""
    path = os.path.join(REFERENCES_DIR, filename)
    if os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()
    return None


def save_output(content, filename):
    """Save content to output directory."""
    path = os.path.join(OUTPUT_DIR, filename)
    with open(path, 'w', encoding='utf-8') as f:
        f.write(content)
    logging.info(f"ğŸ’¾ Saved final HTML to {path}")


def auto_select_speech_register(content: str) -> dict:
    """
    ì½˜í…ì¸  ë¶„ì„ í›„ ê°€ì¥ ì í•©í•œ ì–´ì²´ë¥¼ ìë™ ì„ íƒ.
    
    ê¸°ë³¸ê°’: í•´ë¼ì²´ (ì „ë¬¸ì /í•™ìˆ ì  ë¸”ë¡œê·¸ ê¸°ë³¸)
    í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ë‹¤ë¥¸ ì–´ì²´ê°€ ë” ì í•©í•˜ë©´ ë³€ê²½.
    
    Args:
        content: ë¶„ì„í•  í…ìŠ¤íŠ¸ ì½˜í…ì¸ 
    
    Returns:
        ì„ íƒëœ ì–´ì²´ ì •ë³´ dict
    """
    content_lower = content.lower()
    
    # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
    scores = {}
    for level, info in SPEECH_REGISTERS.items():
        score = 0
        for keyword in info.get('keywords', []):
            if keyword in content_lower:
                score += 1
        scores[level] = score
    
    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì–´ì²´ ì„ íƒ (ë™ì ì´ë©´ í•´ë¼ì²´ ìš°ì„ )
    best_level = 1  # ê¸°ë³¸: í•´ë¼ì²´
    best_score = scores.get(1, 0)
    
    for level, score in scores.items():
        if score > best_score:
            best_level = level
            best_score = score
    
    selected = SPEECH_REGISTERS[best_level]
    logging.info(f"ğŸ¯ ì–´ì²´ ìë™ ì„ íƒ: {selected['name']} (í‚¤ì›Œë“œ ë§¤ì¹­: {best_score}ê°œ)")
    return selected


def auto_construct_persona(input_text: str) -> dict:
    """
    ì½˜í…ì¸  ë¶„ì„ í›„ Writer/Reader í˜ë¥´ì†Œë‚˜ ìë™ êµ¬ì„±.
    
    Agentê°€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ í˜ë¥´ì†Œë‚˜ë¥¼ ìë™ ìƒì„±.
    ì‚¬ìš©ì ì…ë ¥ ì—†ì´ One-Clickìœ¼ë¡œ ì§„í–‰.
    
    Args:
        input_text: ë¶„ì„í•  ì…ë ¥ í…ìŠ¤íŠ¸
    
    Returns:
        ìë™ ìƒì„±ëœ í˜ë¥´ì†Œë‚˜ dict
    """
    signal("ì½˜í…ì¸  ë¶„ì„ í›„ í˜ë¥´ì†Œë‚˜ ìë™ êµ¬ì„± ì¤‘...")
    
    # ì½˜í…ì¸ ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ ì „ë¬¸ ë¶„ì•¼ ì¶”ë¡ 
    # (ì‹¤ì œë¡œëŠ” LLMì´ ë¶„ì„, ì—¬ê¸°ì„œëŠ” íœ´ë¦¬ìŠ¤í‹± ì‚¬ìš©)
    
    # ê¸°ìˆ  ê´€ë ¨ í‚¤ì›Œë“œ
    tech_keywords = ['í”„ë¡œê·¸ë˜ë°', 'ì½”ë”©', 'SQL', 'ë°ì´í„°ë² ì´ìŠ¤', 'API', 'ì•Œê³ ë¦¬ì¦˜']
    science_keywords = ['ë¬¼ë¦¬', 'í™”í•™', 'ìƒë¬¼', 'ì—´ì—­í•™', 'ì—ë„ˆì§€', 'ë¶„ì']
    business_keywords = ['ë§ˆì¼€íŒ…', 'ë¹„ì¦ˆë‹ˆìŠ¤', 'ê²½ì˜', 'íˆ¬ì', 'ì°½ì—…']
    life_keywords = ['ì¼ìƒ', 'ì—¬í–‰', 'ìŒì‹', 'ìš”ë¦¬', 'ë¦¬ë·°', 'í›„ê¸°']
    
    text_lower = input_text.lower()
    
    # ë¶„ì•¼ íŒë³„
    expertise = "General Expert"
    if any(k in text_lower for k in tech_keywords):
        expertise = "Technology & Development"
    elif any(k in text_lower for k in science_keywords):
        expertise = "Science & Engineering"
    elif any(k in text_lower for k in business_keywords):
        expertise = "Business & Marketing"
    elif any(k in text_lower for k in life_keywords):
        expertise = "Lifestyle & Experience"
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ë¡œ ë…ì ìˆ˜ì¤€ ì¶”ë¡ 
    text_length = len(input_text)
    if text_length > 10000:
        reader_level = "Expert"
        mental_state = "Deep Analyst"
    elif text_length > 5000:
        reader_level = "Intermediate"
        mental_state = "Strategic Mentor"
    else:
        reader_level = "Beginner"
        mental_state = "Clear Explainer"
    
    persona = {
        "writer": {
            "expertise": expertise,
            "mental_state": mental_state,
            "tone": "",  # ì–´ì²´ ì„ íƒ í›„ ì„¤ì •
            "image_strategy": "Photorealistic images with handwritten Korean labels, hosted on GitHub"
        },
        "reader": {
            "background": f"Target audience for {expertise}",
            "needs": "Clear explanation with examples",
            "intellectual_level": reader_level
        }
    }
    
    logging.info(f"ğŸ­ í˜ë¥´ì†Œë‚˜ ìë™ êµ¬ì„±: Writer={expertise}/{mental_state}, Reader={reader_level}")
    return persona


def validate_prerequisites() -> bool:
    """
    Validate that all prerequisites are met before starting.
    
    Returns:
        True if all prerequisites are met.
    
    Raises:
        FileNotFoundError: If required files are missing.
    """
    # Check input directory
    if not os.path.exists(INPUT_DIR):
        raise FileNotFoundError(f"âŒ Input directory '{INPUT_DIR}' not found.")
    
    # Check for input files
    input_files = [f for f in os.listdir(INPUT_DIR) if f.endswith('.txt') or f.endswith('.html')]
    if not input_files:
        raise FileNotFoundError(f"âŒ No input files (.txt or .html) found in '{INPUT_DIR}/'")
    
    # Check references directory
    if not os.path.exists(REFERENCES_DIR):
        logging.warning(f"âš ï¸ References directory '{REFERENCES_DIR}' not found. Creating...")
        os.makedirs(REFERENCES_DIR)
    
    # Check output directory
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    
    return True


def main():
    """
    Main orchestration function - ONE CLICK workflow.
    
    ëª¨ë“  ì„¤ì •ì´ ìë™ìœ¼ë¡œ ì§„í–‰ë¨:
    1. Prerequisites ê²€ì¦
    2. ì½˜í…ì¸  ë¡œë“œ
    3. í˜ë¥´ì†Œë‚˜ ìë™ êµ¬ì„± (Agentê°€ ë¶„ì„)
    4. ì–´ì²´ ìë™ ì„ íƒ (Agentê°€ ë¶„ì„)
    5. Scrutiny Loop ì‹¤í–‰
    6. ê²°ê³¼ ì €ì¥
    """
    signal("Entering One-Click Meta Pipeline: 'BLOG FACTORY' v2.0")
    
    # Step 0: Validate prerequisites
    try:
        validate_prerequisites()
    except FileNotFoundError as e:
        logging.error(str(e))
        return
    
    # Load input content
    files = [f for f in os.listdir(INPUT_DIR) if f.endswith('.txt')]
    html_files = [f for f in os.listdir(INPUT_DIR) if f.endswith('.html')]
    
    original_text = ""
    if files:
        original_text = read_input(files[0])
    
    # Step 1: AUTO - Construct Persona
    signal("Step 1: í˜ë¥´ì†Œë‚˜ ìë™ êµ¬ì„± (Agent Analyzing...)")
    persona = auto_construct_persona(original_text)
    
    # Step 2: AUTO - Select Speech Register
    signal("Step 2: ì–´ì²´ ìë™ ì„ íƒ (Agent Analyzing...)")
    speech_register = auto_select_speech_register(original_text)
    
    # Sync persona with speech register
    persona['writer']['tone'] = f"{speech_register['name']} ì‚¬ìš©"
    persona['speech_register'] = speech_register
    
    _manage_persona_context(persona)
    signal("í˜ë¥´ì†Œë‚˜ ë° ì–´ì²´ ìë™ ì„¤ì • ì™„ë£Œ. Engine Synchronized.")
    
    # Display auto-configuration summary
    print("\n" + "="*60)
    print("âœ… ìë™ ì„¤ì • ì™„ë£Œ (Auto-Configuration Complete)")
    print("="*60)
    print(f"  ğŸ“ ì–´ì²´: {speech_register['name']}")
    print(f"  ğŸ­ Writer: {persona['writer']['expertise']} / {persona['writer']['mental_state']}")
    print(f"  ğŸ‘¤ Reader: {persona['reader']['intellectual_level']}")
    print(f"  ğŸ“Œ í—ˆìš© ì¢…ê²°ì–´ë¯¸: {', '.join(speech_register['examples'].get('í‰ì„œ', [])[:4])}")
    print("="*60 + "\n")
    
    # Step 3: Load HTML content
    if html_files:
        with open(os.path.join(INPUT_DIR, html_files[0]), 'r', encoding='utf-8') as f:
            current_html = f.read()
        filename = html_files[0]
    else:
        signal("No HTML file found. HTML generation from TXT is required.")
        filename = files[0].replace('.txt', '.html') if files else "output.html"
        current_html = "<!-- Generated Draft Placeholder -->"
    
    # Step 4: Recursive Scrutiny Loop
    signal("Beginning Scrutiny Loop. Standing by for reports.")
    for attempt in range(1, MAX_RETRIES + 1):
        logging.info(f"ğŸ”„ Scrutiny Cycle #{attempt} Start")
        
        # Engineering + Linguistic + Image Scrutiny
        report = "\n".join([
            _audit_linguistic_quality(current_html, persona),
            _audit_design_and_image(current_html, json.dumps(persona)),
            _audit_image_placement(current_html, persona),
            _validate_technical_constraints(current_html)
        ])
        
        print("\n" + "-"*40)
        print(f"ğŸ“‹ Scrutiny Report (Cycle #{attempt})")
        print("-"*40)
        print(report)
        print("-"*40 + "\n")
        
        if "âŒ" in report:
            signal(f"Red Signal (âŒ) on Cycle #{attempt}. Manual/LLM correction required...")
            # In auto mode, this would call LLM for correction
            break
        else:
            signal(f"Green Signal (âœ…) on Cycle #{attempt}. Content logic verified.")
            break
    
    # Step 4.5: Generate Blog Tags (Auto Briefing)
    signal("íƒœê·¸ ìë™ ìƒì„± ë° ë¸Œë¦¬í•‘ ì¤‘...")
    tags_briefing = _generate_blog_tags(current_html, persona)
    print("\n" + "="*60)
    print(tags_briefing)
    print("="*60 + "\n")
    
    # Step 5: Final Save
    save_output(current_html, f"final_{filename}")
    signal("Process Complete. Check 'output/' directory for results.")


if __name__ == "__main__":
    main()
